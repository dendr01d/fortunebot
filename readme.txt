Because I'm a dumb idiot and I need to write down how this all fits together
And also to explain to anybody actually interested enough to look into this project

main.py is the driver of the program
It authorizes itself with twitter, builds the model from the corpus, then runs the main loop

The corpora are just various lists of quotes and proverbs I compiled. It may be inefficient to build the model from scratch every time the bot is run, but it's not like it's expensive enough of a process to matter

The main loop does this in order:
-check if enough time has passed to tweet. If it has:
	-spit out a new tweet generated by the model
	-figure out how long to wait until tweeting again

markov.py contains all the nonsense for building the model
feed it a corpus of text and it'll analyze it to build a simple markov graph

markov2.py implements a slightly more sophisticated model called an Additive Markov Chain
It can produce more cohesive text, but it needs larger corpora to ensure it doesn't just regurgitate the examples

test_* scripts test their respective class functionality or the tweepy API, respectively

Stuff I may want to implement later:
-lucky numbers
-let people tweet pictures of fortunes to the bot, then have it read them and add them to the corpus
-when people like or retweet a fortune, reinforce the connections that built it (just feed them back into the model?) so that it'll make more like it
-Occasionally mutate words, let the aforementioned reinforcement build more novel connections?
